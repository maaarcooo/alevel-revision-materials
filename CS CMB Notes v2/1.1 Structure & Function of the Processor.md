# 1.1 Structure & Function of the Processor

## Components of a Processor

The **processor (CPU)** is responsible for processing all data within the computer. It executes instructions which allows programs to run.

### The Arithmetic and Logic Unit (ALU)

The **ALU** completes all **arithmetical and logical operations**:

- **Arithmetical operations**: Mathematical operations such as addition, subtraction, multiplication, and division on fixed or floating point numbers
- **Logical operations**: Boolean logic operations such as AND, OR, NOT, and XOR

The ALU contains several components:
- **Arithmetic circuit** - carries out arithmetic operations
- **Logic circuit** - carries out logical operations
- **Registers** - additional registers to store data
- **Status flags** - including overflow flags (value too large for register) and zero flags
- **Buses** - transport data within the ALU and to other CPU parts

### The Control Unit (CU)

The **Control Unit** directs the operations of the CPU. Its functions include:

- Controlling and coordinating the activities of the CPU
- Managing the flow of data between the CPU and other devices
- Accepting the next instruction
- Decoding instructions
- Storing the resulting data back in memory
- Generating timing signals

### Registers

**Registers** are **temporary storage/memory locations inside the CPU** used for a **single specific purpose**. They have a **faster access speed** than RAM or secondary storage. All arithmetic, logical, and shift operations occur in these registers.

| Register | Purpose |
|----------|---------|
| **Program Counter (PC)** | Holds the **address of the next instruction** to be executed |
| **Accumulator (ACC)** | Stores the **results from calculations** |
| **Memory Address Register (MAR)** | Holds the **address of a location** that is to be read from or written to |
| **Memory Data Register (MDR)** | Temporarily stores **data that has been read** or data that needs to be written |
| **Current Instruction Register (CIR)** | Holds the **current instruction** being executed, divided into **operand and opcode** |

### Buses

**Buses** are a set of **parallel wires** which connect **two or more components** inside the CPU. The three buses collectively form the **system bus**.

The **width of the bus** is the number of parallel wires it has. Bus width is **directly proportional** to the **number of bits** that can be transferred **simultaneously**. Buses are typically 8, 16, 32, or 64 wires wide.

| Bus | Purpose | Direction |
|-----|---------|-----------|
| **Data Bus** | Transports **data and instructions** between components | **Bi-directional** |
| **Address Bus** | Transmits **memory addresses** specifying where data is to be sent to or retrieved from. Width is proportional to the **number of addressable memory locations** | Uni-directional |
| **Control Bus** | Transmits **control signals** between internal and external components. Coordinates the use of address and data buses | **Bi-directional** |

**Control signals include:**
- **Bus request** - device requesting use of data bus
- **Bus grant** - CPU has granted access to data bus
- **Memory write** - data written to addressed location
- **Memory read** - data read from specific location to data bus
- **Interrupt request** - device requesting access to CPU
- **Clock** - synchronises operations

---

## Assembly Language

**Assembly code** uses **mnemonics** to represent instructions (e.g., ADD represents addition). This is a simplified way of representing **machine code**.

Instructions are divided into **operand** and **opcode** in the CIR:
- **Opcode** - specifies the **type of instruction** to be executed
- **Operand** - contains the **data** or the **address of the data** upon which the operation is performed

---

## Fetch-Decode-Execute Cycle

The **fetch-decode-execute cycle (FDE cycle)** is the **sequence of operations** completed to execute an instruction.

### Fetch Phase
1. Address from the **PC** is copied to the **MAR**
2. The data from the MAR is sent across the **address bus** with the instruction to read the data sent across the **control bus**
3. Instruction held at that address is copied to **MDR** via the **data bus**
4. **Simultaneously**, the contents of the **PC are incremented by 1**
5. The value held in the MDR is copied to the **CIR**

### Decode Phase
1. The contents of **CIR are split into operand and opcode**
2. This is sent to the **CU** to be decoded

### Execute Phase
The decoded instruction is executed. Which registers are used depends on the instruction:

- **INP** - the ACC stores the inputted value
- **OUT** - outputs the value currently in the ACC
- **LDA** - data sent from RAM (address in MAR) to MDR via data bus
- **STA** - value from ACC sent to MDR, then to RAM (address in MAR)
- **ADD/SUB** - values passed to ALU, operation performed, result stored in ACC
- **BRA/BRZ/BRP** - comparison takes place in ALU

---

## Factors Affecting CPU Performance

### Clock Speed

The **clock speed** is determined by the **system clock** - an electronic device which generates signals, switching between 0 and 1. All processor activities begin on a **clock pulse**, and each CPU operation starts as the clock changes from 0 to 1.

- **Clock speed** = time taken for one clock cycle to complete
- Measured in **Hz** (1 cycle per second = 1 Hz)
- Typical computer: **2.3 GHz** = 2,300,000,000 cycles per second
- Higher clock speed = **more instructions per second** = faster task completion

### Number of Cores

A **core** is an **independent processor** able to run its own fetch-execute cycle.

- Multiple cores can complete **more than one fetch-execute cycle** simultaneously (**parallel processing**)
- Dual core can theoretically complete tasks twice as fast as single core
- However, **not all programs can utilise multiple cores efficiently** as they haven't been designed to do so
- Some **tasks cannot be split between cores**
- Time is spent **organising tasks between cores**

### Amount and Type of Cache Memory

**Cache memory** is the **CPU's onboard memory**. Instructions fetched from main memory are copied to cache, so if required again, they can be accessed **quicker**. As cache fills up, unused instructions are replaced.

Cache is **closer to the CPU** than RAM, therefore faster to retrieve data from.

| Cache Type | Properties |
|------------|------------|
| **Level 1 Cache** | Very fast memory cells with **small capacity** (2-64KB). One for each core. |
| **Level 2 Cache** | Relatively fast memory cell with **medium capacity** (256KB-2MB). Shared between cores. |
| **Level 3 Cache** | Much **larger and slower** memory cell. Sits on motherboard. |

---

## Pipelining *(A Level Only)*

**Pipelining** is the process of completing the fetch, decode, and execute cycles of **three separate instructions simultaneously**, holding appropriate data in a **buffer** close to the CPU until required.

While one instruction is being **executed**, another can be **decoded**, and another **fetched**.

| | Fetch | Decode | Execute |
|------|-------|--------|---------|
| Step 1 | Instruction A | | |
| Step 2 | Instruction B | Instruction A | |
| Step 3 | Instruction C | Instruction B | Instruction A |
| Step 4 | Instruction D | Instruction C | Instruction B |

**Purpose:** Reduces the amount of the CPU kept **idle** and reduces **latency**.

**Types of pipelining:**
- **Instruction pipelining** - separating the instruction into fetching, decoding, and executing
- **Arithmetic pipelining** - breaking down arithmetic operations and overlapping them

**Important:** In the case of a **branch**, the **pipeline is flushed** (contents discarded as subsequent fetched instructions may be incorrect).

---

## Computer Architecture

### Von Neumann Architecture

Von Neumann architecture includes basic components with a **shared memory** and **shared data bus** for both data and instructions. Built on the **stored program concept**.

**Components:**
- **Control Unit (CU)** - controls operation of processor, retrieves/decodes/executes instructions
- **Arithmetic Logic Unit (ALU)** - performs arithmetic and logic operations
- **Special registers** within the CPU
- **Single set of buses** connecting CPU to memory and I/O
- **Memory (RAM)** - stores both data and instructions in the **same format**

### Harvard Architecture

Harvard architecture has **physically separate memories** for instructions and data, more commonly used with **embedded processors**.

**Key differences from Von Neumann:**
- **Separate memory units** for data and instructions
- **Separate buses** for data and instructions
- Instructions and data can be **fetched in parallel**

**Advantages:**
- Useful when memories have **different characteristics** (instructions may be read-only, data may be read-write)
- Can **optimise size of individual memory cells** and buses depending on needs
- Greater speed and efficiency through **concurrent access**

### Comparison Table

| Von Neumann Advantages | Harvard Advantages |
|-----------------------|-------------------|
| **Cheaper to develop** as control unit is easier to design | **Quicker execution** as data and instructions can be fetched in parallel |
| Programs can be **optimised in size** | Memories can be **different sizes**, more efficient use of space |

### Contemporary Processor Architecture

Contemporary processors use a **combination of Harvard and Von Neumann** architecture:
- **Von Neumann** - when working with data and instructions in **main memory**
- **Harvard** - divides **cache into instruction cache and data cache**

**Additional contemporary features:**
- **Pipelining** - concurrent instruction processing
- **Multiple cores** - separate processing units
- **Virtual cores/Hyperthreading** - physical core acts as two virtual cores
- **Onboard graphics** - built-in graphics processing circuitry
- **Performance boosting mode** - temporarily increased clock speed
- **Out of order execution** - instructions executed before earlier ones if ready
- **Super scalar** - multiple instructions executed simultaneously

---

## Key Exam Points

1. Be **specific about register contents** when answering questions about the FDE cycle
2. Understand how assembly language instructions use different registers
3. Know the **trade-offs** of each performance factor (e.g., more cores doesn't always mean faster)
4. Distinguish between **concurrent** (pipelining) and **parallel** (multiple cores) processing
5. Contemporary processors combine Von Neumann and Harvard architectures
