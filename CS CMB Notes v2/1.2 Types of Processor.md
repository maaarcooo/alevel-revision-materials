# 1.2 Types of Processor

## Specification Coverage
- 1.1.2 a) RISC and CISC processors and their differences
- 1.1.2 b) GPUs and their uses
- 1.1.2 c) Multicore and parallel systems

---

## RISC vs CISC Processors

Every processor has an **instruction set** - a collection of instructions it can execute. Different processors have different instruction sets, and there are two main design philosophies.

### RISC (Reduced Instruction Set Computer)

RISC processors use a **smaller instruction set** containing simpler instructions.

**Key characteristics:**
- Each instruction takes **one clock cycle** to execute
- Instructions are simpler and more uniform in format
- **Fewer addressing modes** available
- **Fewer general purpose registers**
- **Fewer transistors** required
- **Well-suited to pipelining** (due to uniform instruction length)
- Compilers are **more complicated** and generate more instructions
- Programs take up **more space in memory** (more lines of code)
- **Requires less power** to operate
- **Cheaper to manufacture**
- Commonly used in **smartphones and tablets**

**Example - Multiplying two values X and Y (RISC):**
```
LDA    R1,    X      ; Load X into register 1
LDA    R2,    Y      ; Load Y into register 2
MULT   R1,    R2     ; Multiply R1 by R2
STO    R1,    X      ; Store result back to X
```

### CISC (Complex Instruction Set Computer)

CISC processors use a **larger instruction set** containing more complex, powerful instructions.

**Key characteristics:**
- Instructions can take **multiple clock cycles** to execute
- Instructions are more complex with variable formats
- **More addressing modes** available
- **More general purpose registers**
- **More transistors** required
- **Not well-suited to pipelining** (variable instruction lengths)
- Compilers are **less complicated** (can use powerful single instructions)
- Programs take up **less space in memory** (fewer lines of code)
- **Requires more power** to operate
- **More expensive to manufacture**
- Many specialised instructions exist, though only a few are commonly used
- Commonly used in **laptops and desktop computers**

**Example - Multiplying two values A and B (CISC):**
```
MULT   A,    B       ; Single instruction performs entire operation
```

### RISC vs CISC Comparison Table

| Feature | RISC | CISC |
|---------|------|------|
| Instruction set size | Smaller, simpler | Larger, more complex |
| Clock cycles per instruction | One | Multiple |
| Transistor count | Fewer | More |
| Pipelining suitability | Well-suited | Not well-suited |
| Compiler complexity | More complicated | Less complicated |
| General purpose registers | Fewer | More |
| Addressing modes | Fewer | More |
| Memory usage | More (longer programs) | Less (shorter programs) |
| Power consumption | Less | More |
| Manufacturing cost | Lower | Higher |
| Typical use | Smartphones, tablets | Laptops, desktops |

### Compatibility

- A program written for a **RISC processor will not work on a CISC processor** (and vice versa)
- A program written for one RISC processor **will not necessarily work on another RISC processor** as they may have different instruction sets

---

## Graphics Processing Unit (GPU)

### What is a GPU?

A **GPU (Graphics Processing Unit)** is a specialised processor designed primarily for **processing graphics** to reduce the load on the CPU.

**Key characteristics:**
- Contains **hundreds or thousands of smaller processing cores**
- Designed to work in **parallel** - performing many operations simultaneously
- Acts as a **co-processor** (secondary processor supplementing the CPU)
- Can be part of a dedicated **graphics card** or **embedded in the CPU**
- Has built-in circuitry/instructions optimised for common graphics operations
- Can perform an instruction on **multiple pieces of data at one time**

### CPU vs GPU

| CPU | GPU |
|-----|-----|
| General purpose processor | Specialised for graphics/parallel tasks |
| Fewer, more powerful cores | Many smaller, simpler cores |
| Optimised for **serial processing** | Optimised for **parallel processing** |
| Handles complex, varied tasks | Handles repetitive, uniform tasks |

### Why GPUs Excel at Graphics

GPUs are efficient at graphics processing because:
- Graphics operations (transforming polygons, shading pixels) involve performing the **same operation on many data points**
- GPUs can execute these repetitive operations simultaneously across many cores
- This allows faster transformation of on-screen graphics than a CPU could achieve

### GPU Uses Beyond Graphics

GPUs have applications in many fields requiring **parallel computation**:

**3D Modelling**
- Rendering lighting effects, textures, and shadows

**Machine Learning**
- Training models on massive datasets (involves many matrix multiplications)
- Making predictions on new data after training

**Data Mining**
- Analysing large amounts of data to find patterns
- Tasks include sorting, searching, pattern recognition, statistical analysis

**Financial Modelling**
- Risk modelling and option pricing
- Running multiple simulations in parallel

**Data Modelling**
- Handling large datasets with complex operations (sorting, filtering)

**Scientific Computing**
- Numerical simulations in physics and engineering
- Solving differential equations
- Matrix multiplication and inversion

**Calculations on Multiple Data Simultaneously**
- Insurance pricing, risk modelling, billing calculations

### Task Suitability for GPUs

GPUs are suited to tasks that utilise:

**Specialist Instructions**
- Operations on matrices, vectors, and geometric transformations
- Originally designed for 3D graphics, now generalised for broader use

**Multiple Cores**
- Tasks that can be broken into smaller independent parts
- Large-scale data processing

**SIMD Processing**
- **Single Instruction Multiple Data** - performing the same operation on multiple data points simultaneously
- Originally designed for operations on multiple pixels/vertices at once
- Common in image processing, simulations, and machine learning

### Benefits of Using a GPU

**Parallel Processing** - Can handle many tasks simultaneously using multiple cores

**Speed** - Parallel execution speeds up tasks involving large data or complex computations

**Efficiency** - Performs more calculations per unit of power compared to CPUs for parallel tasks

**Note:** A system cannot use only a GPU - the CPU assigns tasks to the GPU.

---

## Multicore and Parallel Systems

### Parallel Processing

**Parallel processing** occurs when a computer uses multiple processors or cores to execute instructions simultaneously.

**Two approaches:**
- Multiple cores work on the **same task** to complete it more quickly
- Multiple cores work on **separate tasks** at the same time

### Multicore Processing

A **multicore processor** contains **more than one processing unit** within a single processor chip. Each core can **independently process instructions at the same time**.

Parallel processing can also be achieved using multiple separate processors (e.g., a CPU working alongside a GPU).

### Benefits of Parallel Processing

| Benefit | Explanation |
|---------|-------------|
| **Speed** | Tasks divided into subtasks executed simultaneously reduce total execution time |
| **Improved performance** | Simultaneous computation on different data subsets (used in machine learning, data mining, scientific computing) |
| **Better resource utilisation** | Multi-core/multiple processors used more effectively |
| **Problem solving** | Large, complex problems that suit parallel processing can be solved more easily |
| **Real-time applications** | Graphics rendering and similar applications become more feasible |

### Limitations of Parallel Processing

| Limitation | Explanation |
|------------|-------------|
| **Limit on maximum speed** | Even with infinite processors, speedup is limited if part of the program cannot be parallelised (Amdahl's Law) |
| **Complex programming** | Writing parallel code is harder than serial code; tasks must be synchronised and data shared correctly |
| **Debugging difficulty** | Harder to debug due to timing-dependent issues and non-deterministic behaviour |
| **Communication overhead** | Communication between processors takes time and resources, potentially outweighing benefits |
| **Limited applicability** | Not all tasks can be parallelised; some must execute serially |

### Benefits of Multicore Processors

**Multitasking**
- Each core handles a different task
- Particularly effective when multiple applications are open simultaneously

**Background Tasks**
- Background operations (e.g., anti-malware scans) can run on a dedicated core
- Reduces impact on user's primary task

**Improved Responsiveness**
- If one program becomes unresponsive, other cores continue running their tasks
- System remains usable even when one application hangs

---

## Key Exam Points

1. **RISC pipelining advantage**: Because each RISC instruction takes exactly one clock cycle, pipelining is straightforward and efficient.

2. **CISC memory efficiency**: Despite needing more complex hardware, CISC programs use less RAM because fewer instructions are needed.

3. **GPU parallel architecture**: GPUs trade individual core power for massive parallelism - ideal for graphics and data-parallel tasks.

4. **Parallel processing is not always beneficial**: The overhead of communication and synchronisation can outweigh benefits for unsuitable tasks.

5. **Program compatibility**: Code must be recompiled for different processor architectures; binary compatibility does not exist between RISC and CISC or between different RISC implementations.
