# 1.2 Types of Processor

## RISC and CISC Processors

A computer processor has an **instruction set** — the set of instructions it can execute to run programs. This varies between processors. There are two main processor architectures:

### RISC (Reduced Instruction Set Computer)

**RISC** processors have a **smaller instruction set** with simpler instructions.

Key characteristics:

- Each instruction takes **one clock cycle** to execute
- **Well-suited for pipelining** due to uniform instruction execution time
- **Compilers are more complicated** and generate more instructions
- **Fewer addressing modes**
- **Fewer general purpose registers**
- **Requires more RAM** to store longer programs
- **Fewer transistors** on the chip
- **Lower power consumption**
- **Cheaper to manufacture**
- Commonly used in **smartphones and tablets**

Example — multiplying two numbers (X and Y):
```
LDA  R1, X
LDA  R2, Y
MULT R1, R2
STO  R1, X
```

### CISC (Complex Instruction Set Computer)

**CISC** processors have a **larger instruction set** with more complex instructions.

Key characteristics:

- Instructions can take **multiple clock cycles** to execute
- **Not well-suited for pipelining** due to variable instruction times
- **Compilers are simpler** as complex operations map directly to single instructions
- **More addressing modes**
- **More general purpose registers**
- **Requires less RAM** as programs are shorter
- **More transistors** on the chip
- **Higher power consumption**
- **More expensive to manufacture**
- Many specialised instructions exist, though only a few are commonly used
- Commonly used in **laptops and desktop computers**

Example — same multiplication:
```
MULT A, B
```

### RISC vs CISC Comparison

| Feature | RISC | CISC |
|---------|------|------|
| Instruction set size | Smaller, simpler | Larger, more complex |
| Clock cycles per instruction | One | Multiple |
| Pipelining | Well-suited | Not well-suited |
| Compiler complexity | More complicated | Less complicated |
| General purpose registers | Fewer | More |
| Addressing modes | Fewer | More |
| RAM usage | More (longer programs) | Less (shorter programs) |
| Transistor count | Fewer | More |
| Power consumption | Lower | Higher |
| Manufacturing cost | Lower | Higher |
| Typical use | Smartphones, tablets | Laptops, desktops |

**Compatibility**: A program written for a RISC processor will **not work on a CISC processor** and vice versa. Even programs written for one RISC processor may not work on another RISC processor if they have different instruction sets.

---

## Graphics Processing Unit (GPU)

A **GPU (Graphics Processing Unit)** is a **co-processor** — a secondary processor designed to supplement the CPU's activities.

### Key Characteristics

- Contains **hundreds or thousands of smaller processing cores**
- Cores work **in parallel**, making GPUs efficient at **repetitive tasks**
- Can perform the **same instruction on multiple pieces of data simultaneously**
- Can be **part of a graphics card** or **embedded in the CPU**
- **CPUs are general-purpose**; **GPUs are designed specifically for graphics** and parallel workloads

### Why GPUs Excel at Certain Tasks

**Specialist instructions**: GPUs execute instructions common in 3D graphics rendering — operations on **matrices**, **vectors**, and **geometric transformations**. These capabilities have been generalised for broader use.

**Multiple cores**: While CPU cores are optimised for **serial processing**, GPU cores are optimised for **parallel processing**. GPUs perform many calculations simultaneously, ideal for tasks divisible into smaller parts.

**SIMD processing**: **Single Instruction Multiple Data (SIMD)** — multiple processing elements perform the same operation on multiple data points simultaneously. GPUs support SIMD as they were designed to process multiple pixels or vertices at once.

### GPU Applications Beyond Graphics

| Application | How GPUs Help |
|-------------|---------------|
| **3D modelling** | Render lighting effects, textures, and shadows |
| **Machine learning** | Training on massive datasets with parallel matrix multiplications; making predictions on new data |
| **Data mining** | Analysing large datasets to find patterns through sorting, searching, pattern recognition, statistical analysis |
| **Data modelling** | Handling large datasets with complex operations like sorting and filtering |
| **Financial modelling** | Running parallel simulations for risk modelling and option pricing |
| **Numerical simulations** | Solving complex physics and engineering models in parallel |
| **Differential equations** | Computations can be parallelised |
| **Matrix operations** | Matrix multiplication and inversion done in parallel |
| **Batch calculations** | Insurance pricing, risk modelling, bill calculations on multiple data simultaneously |

### Benefits of Using a GPU

- **Parallel processing**: Handle many tasks simultaneously as multicore processors
- **Speed**: Parallel processing accelerates tasks involving large data or complex computations
- **Efficiency**: More calculations per unit of power consumed compared to CPUs for parallel tasks

**Note**: A system cannot use only a GPU — the **CPU assigns tasks to the GPU**.

---

## Multicore and Parallel Processing

### Parallel Processing

**Parallel processing** uses **multiple cores** to process data simultaneously.

- Each core can work on the **same task** (completing it faster)
- Or each core can work on **separate tasks** at the same time

### Multicore Processing

A **multicore system** has **more than one processing unit** within a single processor chip. Each unit can **independently process instructions at the same time**.

Parallel processing can also be achieved using **multiple processors** together (e.g., a CPU and GPU working in tandem).

### Benefits and Limitations of Parallel Processing

| Benefits | Limitations |
|----------|-------------|
| **Speed**: Dividing tasks into subtasks that execute simultaneously reduces total execution time | **Maximum speed limit**: Even with infinite processors, there is a limit if part of the program cannot be parallelised (Amdahl's Law) |
| **Improved performance**: Simultaneous computation on different data subsets (useful in machine learning, data mining, scientific computing) | **Complex programming**: Harder to write parallel code than serial code; requires synchronisation and correct data sharing |
| **Better resource utilisation**: Multi-core or multiple processors used more effectively | **Debugging difficulty**: More difficult to debug due to precise timing of events and non-deterministic behaviour |
| **Problem solving**: Large, complex problems that suit parallelisation can be solved more easily | **Communication overhead**: Communication between processors takes time and resources, potentially outweighing benefits |
| **Real-time applications**: Graphics rendering and real-time systems are more feasible | **Limited applicability**: Not all tasks can be parallelised; some must execute serially |

### Benefits of Multicore Processors

**Multitasking**: Each core handles a different task — effective when multiple applications are open simultaneously.

**Background tasks**: Background processes (e.g., anti-malware scans) can run on one core without significantly impacting the user's primary task on another core.

**Improved responsiveness**: If one program becomes unresponsive, other cores continue running their tasks, preventing system-wide slowdown.
